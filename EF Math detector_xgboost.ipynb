{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a162ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix, accuracy_score, f1_score, cohen_kappa_score\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_features = pd.read_csv(\"Features_aggToPhase_2021-12-26.csv\") #added # of n.,v.,pronouns.\n",
    "df_label = pd.read_csv(\"Cuethink_Coding_JoyceAlexis_Dec29.csv\").drop(columns = ['index','filename','X'])\n",
    "\n",
    "\n",
    "# join features with with labels\n",
    "df = pd.merge(df_label, df_features,on = ['user_id','thinklet_id']) #inner join (excluded thinklets that are incomplete, features were extracted for complete thinklets only)\n",
    "\n",
    "# drop columns and inpute missing value as 0\n",
    "df_train = df.drop(['thinklet_id', 'assignment_name','strategiesSelected'], axis=1).fillna(0) # drop'strategiesSelected'\n",
    "\n",
    "\n",
    "# extract features as X\n",
    "X = df_train.drop(['Numerical_Representation','Contextual_Representation',\n",
    "                     'Strategy_Orientation','Outcome_Orientation','Data_Transformation'], axis=1)\n",
    "\n",
    "# extract the prediction variable as y\n",
    "y = df_train.Data_Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fe988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data \n",
    "\n",
    "# Construct grouping data to ensure the same student does not end up in both training and test splits\n",
    "group_dict = dict()\n",
    "groups = np.array([])\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    s_id = row['user_id']\n",
    "    if s_id not in group_dict:\n",
    "        group_dict[s_id] = index\n",
    "    groups = np.append(groups, group_dict[s_id])\n",
    "    \n",
    "# Set up the splitter with 10 splits\n",
    "gkf = GroupKFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "\n",
    "# setup the XGBoost classifier\n",
    "classifier = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# set up storage arrays for each round of validation\n",
    "roc_auc_scores = np.array([])\n",
    "accuracy_scores = np.array([])\n",
    "cohen_kappa_scores = np.array([])\n",
    "f1_scores = np.array([])\n",
    "list_shap_values = list()\n",
    "list_test_sets = list()\n",
    "\n",
    "# split, train, test and store performance metrics\n",
    "for train_index, test_index in gkf.split(X, y, groups=groups):\n",
    "    \n",
    "    # Get the training and test data from the dataset for this group\n",
    "    X_train = X.iloc[train_index].drop(['user_id'], axis=1)\n",
    "    X_test = X.iloc[test_index].drop(['user_id'], axis=1)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    # train classifier on this round of training group\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # test classifier on this round of testing group\n",
    "    predictions = classifier.predict(X_test)\n",
    "    predictions_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "    # compute some metrics and store them for averaging later on\n",
    "    roc_auc_scores = np.append(roc_auc_scores, roc_auc_score(y_test, predictions))\n",
    "    accuracy_scores = np.append(accuracy_scores, accuracy_score(y_test, predictions))\n",
    "    cohen_kappa_scores = np.append(cohen_kappa_scores, cohen_kappa_score(y_test, predictions))\n",
    "    f1_scores = np.append(f1_scores, f1_score(y_test, predictions))\n",
    "\n",
    "\n",
    "# print mean scores for the 10-fold CV\n",
    "print(\"average roc_auc score: \", np.round(roc_auc_scores.mean(), 3))\n",
    "print(\"stdv roc_auc score: \", np.round(roc_auc_scores.std(), 3))\n",
    "print(\"max roc_auc score: \", np.round(roc_auc_scores.max(), 3))\n",
    "print(\"average Cohen's Kappa score: \", np.round(cohen_kappa_scores.mean(), 3))\n",
    "print(\"stdev Cohen's Kappa score: \", np.round(cohen_kappa_scores.std(), 3))\n",
    "print(\"average F1 score: \", np.round(f1_scores.mean(), 3))\n",
    "print(\"average Accuracy score: \", np.round(accuracy_scores.mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'detector_DT.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
